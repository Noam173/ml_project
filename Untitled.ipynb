{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7261df42-77b0-4a13-85a4-7401769edf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import  ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c55da63b-b03c-49d6-8fc2-138ef3fa3657",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms=transforms.Compose([transforms.Resize((256,256)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a0d7538-e294-443f-8726-90580dafd83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Real_vs_Ai(Dataset):\n",
    "    def __init__(self, data_dir, transform=transforms):\n",
    "        self.data=ImageFolder(data_dir, transform=transforms)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63f3ab14-8d25-4e09-ac02-4484023d8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=Real_vs_Ai('classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71c95b6f-218b-48e5-b858-3f50054b546c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79950"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3be6d757-9c20-403e-8055-b5def70352d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label=dataset[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c72dc6a-c2ff-4159-ae5c-ae37f48e1366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5353967-75ae-43d0-a5fd-30154d4bb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader=DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d597388a-023b-4f39-8046-6979e52ded88",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data, target\u001b[38;5;241m=\u001b[39mdataloader\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "data, target=dataloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fbe8b0-df6e-41fe-a509-d44e1a3cb7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.module):\n",
    "    super(Model, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ff24503d-d937-47a3-894d-822b2e343680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        kernel_size = 3\n",
    "        super(MyModel, self).__init__()\n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2)  # Corrected typo here\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size)  # Corrected input channels to 32\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.maxpool2 = nn.MaxPool2d(2)  # Corrected typo here\n",
    "        self.conv3 = nn.Conv2d(64, 16, kernel_size)\n",
    "        self.maxpool3 = nn.MaxPool2d(2)\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        self.dense1=nn.Linear(1, 256)\n",
    "        self.dense2=nn.Linear(256,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)  # Applied first pooling\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2(x)  # Applied second pooling\n",
    "        x = self.conv3(x)\n",
    "        x=self.maxpool3(x)\n",
    "        x=self.avgpool(x)\n",
    "        x=self.dropout2(x)\n",
    "        x=self.dense1(x)\n",
    "        x=self.dense2(x)\n",
    "        return x\n",
    "\n",
    "# Example input: A batch of 1 image, 3 channels (RGB), 256x256 size\n",
    "input_tensor = torch.randn(1, 3, 256, 256)  # Batch size of 1, RGB image of size 256x256\n",
    "\n",
    "# Initialize the model\n",
    "model = MyModel()\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)  # Forward pass with input_tensor\n",
    "print(output.shape)           # Print output shape after convolution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
